
### Part A
###### Goal : Investigate the performance of a number of machine learning procedures on "P3_Data.csv" dataset. Perform a comparative study of the following machine learning procedures:  Linear Regression;  at least two more ML technique to predict the target value.
# HERE YOU WILL WRITE CODE TO TEST A NUMBER OF PREDICTORS
# AND FINALLY CHOOSE AND TRAIN THE PREDICTOR THAT YOU WILL BE USING FOR PART B

#import relevant libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore", message="The default value of numeric_only in DataFrame.corr is deprecated.")

# Changing numpy settings so that it prints arrays without truncation.
np.set_printoptions(threshold=np.inf)

# Load the dataset
df = pd.read_csv('CE802_P3_Data.csv')

# quick look to data
#Print the first 5 rows of the dataframe.
df.head()
###### Basic Exploratory Data Analysis (EDA) and statistical analysis
# summary of statistics
df.info(verbose=True)
df.describe().T
# A value of zero does not make sense and thus indicates missing value.
# Following columns or variables have an invalid zero value:F23 and F27.
# Replace zeros with nan since after that counting them would be easier and zeros need to be replaced with suitable values
df_copy = df.copy(deep = True)
df_copy[['F23','F27']] = df_copy[['F23','F27']].replace(0,np.NaN)

## showing the count of Nans
print(df_copy.isnull().sum())
###### Data Visualisation
# To fill these Nan values the data distribution needs to be understood
p = df.hist(figsize = (20,20),color = "#5F9EA0")
# Lets see the distributions of each features even more clearly using desity plots

df.plot(kind = "density", subplots = True, layout = (6,6), sharex =False, figsize = (14,10))
plt.show();
# Lets see the boxplots to check any outliers in our data

df.plot(kind = "box", subplots = True, layout = (6,6), sharex = False, sharey = False, figsize = (10,10))
plt.show();
###### We can see that some amount of outliers is present.
#Aiming to impute nan values for the columns in accordance with their distribution
df_copy['F23'].fillna(df_copy['F23'].mean(), inplace = True)
df_copy['F27'].fillna(df_copy['F27'].mean(), inplace = True)
#Plotting after Nan removal
p = df_copy.hist(figsize = (20,20),color = "#5F9EA0")
#check for missing values
df.isna().sum()
###### No missing values found.
# Lets see the correlation matrix between all features
df.corr()
#get correlations of each features in dataset
corrmat = df.corr()
top_corr_features = corrmat.index
plt.figure(figsize=(25,25))
#plot heat map
g=sns.heatmap(df[top_corr_features].corr(),annot=True,cmap="Blues")
# Scatterplot
from pandas.plotting import scatter_matrix
p=scatter_matrix(df,figsize=(18, 18))
###### Checking value counts of categorical columns
categorical_cols = ['F29', 'F32']

plt.figure(figsize = (10, 20))
plotnumber = 1

# plotting the countplot of each categorical column.

for i in range(len(categorical_cols)):
    if plotnumber <= 8:
        ax = plt.subplot(4, 2, plotnumber)
        sns.countplot(x = categorical_cols[i], data = df, ax = ax, palette='dark')
        plt.title(f"\n{categorical_cols[i]} Value Counts\n", fontsize = 14)
        
    plotnumber += 1

plt.tight_layout()
plt.show()
###### From the above plots, we can conclude that F29 has more values for 'High'. F32 has more values for 'Rest' followed by 'Europe'
###### Exploring relation of categorical columns with target/output column
# Get the categorical columns in the data set
categorical_columns = df.select_dtypes(include=['object']).columns

# Create a subplot grid based on the number of categorical columns
fig, axs = plt.subplots(1, len(categorical_columns), figsize=(len(categorical_columns)*5, 5))

# Loop through each categorical column and create a pie chart on a subplot
for i, col in enumerate(categorical_columns):
    # Get the value counts for the column
    counts = df[col].value_counts()
    
    # Plot the pie chart on the subplot
    axs[i].pie(counts, labels=counts.index, autopct='%1.1f%%', startangle=90)
    
    # Add the column name and title to the subplot
    axs[i].set_ylabel('')
    axs[i].text(-1.5, 1.2, col, fontsize=14, fontweight='bold', va='center')
    
# Add a suptitle for the entire figure
fig.suptitle("Categorical Column Distributions", fontsize=20)

# Adjust the spacing between subplots
fig.tight_layout(pad=3)

# Display the plot
plt.show()

###### Exploring relation of numerical columns with target column
import seaborn as sns

numerical_columns = df.select_dtypes(include=['float64','int64']).columns

fig, axes = plt.subplots(1, len(numerical_columns), figsize=(len(numerical_columns)*3, 3))

for i, col in enumerate(numerical_columns):
    sns.histplot(df[col], ax=axes[i])
    axes[i].set_title(col)

fig.suptitle("Numerical Columns Distribution", fontsize=20, y=1.05)
plt.tight_layout()
plt.show()
print(numerical_columns)
###### Feature Engineering
###### Encoding And Scaling the data
# Convert categorical columns to numeric using LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df['F29'] = le.fit_transform(df['F29'])
df['F32'] = le.fit_transform(df['F32'])

# Standardize numerical columns using StandardScaler
num_cols = ['F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'F10',
            'F11', 'F12', 'F13', 'F14', 'F15', 'F16', 'F17', 'F18', 'F19', 'F20',
            'F21', 'F22', 'F23', 'F24', 'F25', 'F26', 'F27','F28','F29','F30','F31','F32','F33','F34']
scaler = StandardScaler()
df[num_cols] = scaler.fit_transform(df[num_cols])

# Show the first five rows of the updated dataset
print(df.head())
###### Declare feature vector and target variable
X = df.iloc[:, :-1]
y = df.iloc[:, -1]
###### Create a Validation Dataset
# Split data into features and target
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

###### Train And Evaluate Models
# Train and Evaluate Models
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.impute import SimpleImputer
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, r2_score

lr = LinearRegression()
dtr = DecisionTreeRegressor(random_state=42)
rfr = RandomForestRegressor(n_estimators=100, random_state=42)

# Define the models
models = {
    "Linear Regression": lr,
    "Decision Tree Regression": dtr,
    "Random Forest Regression": rfr,
}

# Train and evaluate the models
rmse_scores = {}
r2_scores = {} 
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    rmse = mean_squared_error(y_test, y_pred, squared=False)
    r2 = r2_score(y_test, y_pred)
    rmse_scores[name] = rmse
    r2_scores[name] = r2  
    print(name)
    print("RMSE:", rmse)
    print("R^2:", r2)
    print()

# Choose the best model
best_model_name = min(rmse_scores, key=rmse_scores.get)
best_model = models[best_model_name]
print("Best Model:", best_model_name)
print("Best RMSE:", rmse_scores[best_model_name])
print("Best R^2:", r2_scores[best_model_name])
print("Weight:", lr.coef_)
print("The intercept is:", lr.intercept_)
###### The Random Forest Regression is the best-performing model, with an R2 score of 0.705 and an RMSE of 105.77.Therefore, we will choose Random Forest Regression for predictions in Part B.
### Part B
###### Goal: Prediction on a hold-out test set.Produce class predictions of the records in the test set using one approach of your choice among those tested in task “a” (for example the one achieving the best performance). Target values are withheld for this test set (i.e. the “Target” column is empty).
# HERE YOU WILL USE THIS TEMPLATE TO SAVE THE PREDICTIONS ON THE TEST SET

# Load the test data
test_df = pd.read_csv('CE802_P3_Test.csv')

# Make sure you work on a copy
test_data = test_df.iloc[:,:-1].copy()
test_data['F29'] = le.fit_transform(test_data['F29'])
test_data['F32'] = le.fit_transform(test_data['F32'])

# Standardize numerical columns using StandardScaler
num_cols = ['F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'F10',
            'F11', 'F12', 'F13', 'F14', 'F15', 'F16', 'F17', 'F18', 'F19', 'F20',
            'F21', 'F22', 'F23', 'F24', 'F25', 'F26', 'F27','F28','F29','F30','F31','F32','F33','F34']
scaler = StandardScaler()
test_data[num_cols] = scaler.fit_transform(test_data[num_cols])
predicted = rfr.predict(test_data) # CHANGE HERE -- use your previously trained predictor and apply it to test_data
                # (test_data can be modified if needed but make sure you don't change the order of the rows)...

# Replace the last (empty) column with your prediction
test_df.iloc[:,-1] = predicted

# Save to the destination file
test_df.to_csv('CE802_P3_Test_Predictions.csv', index=False, float_format='%.8g')

# IMPORTANT!! Make sure only the last column has changed
assert pd.read_csv('CE802_P3_Test.csv').iloc[:,:-1].equals(pd.read_csv('CE802_P3_Test_Predictions.csv').iloc[:,:-1])
